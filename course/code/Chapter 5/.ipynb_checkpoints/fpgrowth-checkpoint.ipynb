{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610d211f",
   "metadata": {},
   "source": [
    "# FP-Growth Algorithm in PySpark\n",
    "\n",
    "This notebook demonstrates how to use the **FP-Growth** algorithm in PySpark for frequent pattern mining and association rule generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0bbf0",
   "metadata": {},
   "source": [
    "## Step 1: Set Up Spark Session\n",
    "We first create a Spark session to work with PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcc554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FP-Growth Example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f5c09d",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare Data\n",
    "We create a sample dataset where each transaction is represented as a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e0f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample transaction data\n",
    "data = [\n",
    "    (0, [\"milk\", \"bread\", \"butter\"]),\n",
    "    (1, [\"milk\", \"bread\"]),\n",
    "    (2, [\"bread\", \"butter\"]),\n",
    "    (3, [\"milk\", \"butter\"]),\n",
    "    (4, [\"bread\"])\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = spark.createDataFrame(data, [\"id\", \"items\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b15980",
   "metadata": {},
   "source": [
    "## Step 3: Apply FP-Growth Algorithm\n",
    "We use PySpark's `FPGrowth` class to find frequent itemsets and generate association rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd502bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "# Initialize FP-Growth model\n",
    "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.4, minConfidence=0.6)\n",
    "\n",
    "# Train the model\n",
    "model = fpGrowth.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba3973",
   "metadata": {},
   "source": [
    "## Step 4: Display Frequent Itemsets\n",
    "We display all the frequent itemsets found by the algorithm that meet the minimum support threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ed3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show frequent itemsets\n",
    "model.freqItemsets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc0b9c7",
   "metadata": {},
   "source": [
    "## Step 5: Generate Association Rules\n",
    "Association rules are generated for itemsets that meet the minimum confidence threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af46fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show association rules\n",
    "model.associationRules.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51bd12",
   "metadata": {},
   "source": [
    "## Step 6: Make Predictions\n",
    "Use the model to predict the frequent itemsets in new transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict frequent itemsets for new data\n",
    "new_data = spark.createDataFrame([\n",
    "    (5, [\"milk\", \"bread\"]),\n",
    "    (6, [\"butter\", \"bread\"])\n",
    "], [\"id\", \"items\"])\n",
    "\n",
    "predictions = model.transform(new_data)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a483eaf4",
   "metadata": {},
   "source": [
    "## Step 7: Stop the Spark Session\n",
    "Finally, we stop the Spark session to release resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fbeec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198cfd84-d270-4140-9a04-1f7c76da8c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
