{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31af8894",
   "metadata": {},
   "source": [
    "# Customer Churn Analysis with PySpark\n",
    "\n",
    "This notebook demonstrates how to process the customer churn dataset using PySpark.\n",
    "\n",
    "### Objectives:\n",
    "- Load the dataset and resolve header/schema issues.\n",
    "- Create a `features` column using `VectorAssembler`.\n",
    "- Convert the `churn` column into a numeric `label` using `StringIndexer`.\n",
    "- Train a Decision Tree model and store it in a file.\n",
    "- Evaluate the model using metrics like confusion matrix, precision, recall, and F1-score.\n",
    "- Plot the ROC curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a77e842",
   "metadata": {},
   "source": [
    "## Step 1: Initialize PySpark and Load Data\n",
    "We'll start by initializing a Spark session and loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390de6ed-f9a2-481e-a1d5-dcca4f9e230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2364ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Customer Churn Analysis\").getOrCreate()\n",
    "\n",
    "# Load the CSV file with inferred schema\n",
    "data = spark.read.csv(\"customer_churn_prod.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows\n",
    "data.show(5)\n",
    "\n",
    "# Print schema to verify column types\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbcfe5a",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "- Identify and drop any unnecessary columns, such as `_c0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the `_c0` column if it exists\n",
    "if \"_c0\" in data.columns:\n",
    "    data = data.drop(\"_c0\")\n",
    "\n",
    "# Verify remaining columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bd70f",
   "metadata": {},
   "source": [
    "## Step 2: Assemble Features\n",
    "Combine numerical columns into a single `features` column using `VectorAssembler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# List of numerical feature columns\n",
    "feature_columns = [\n",
    "    \"account_length\", \"number_vmail_messages\", \"total_day_minutes\",\n",
    "    \"total_day_calls\", \"total_day_charge\", \"total_eve_minutes\",\n",
    "    \"total_eve_calls\", \"total_eve_charge\", \"total_night_minutes\",\n",
    "    \"total_night_calls\", \"total_night_charge\", \"total_intl_minutes\",\n",
    "    \"total_intl_calls\", \"total_intl_charge\", \"number_customer_service_calls\"\n",
    "]\n",
    "\n",
    "# Assemble features into a vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Show the first few rows with the new features column\n",
    "data.select(\"features\", \"churn\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03033adc",
   "metadata": {},
   "source": [
    "## Step 3: Index the `churn` Column\n",
    "Convert the `churn` column into a numeric `label` column using `StringIndexer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad8b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Index the `churn` column\n",
    "indexer = StringIndexer(inputCol=\"churn\", outputCol=\"label\")\n",
    "data = indexer.fit(data).transform(data)\n",
    "\n",
    "# Show the updated DataFrame with the label column\n",
    "data.select(\"features\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06995582",
   "metadata": {},
   "source": [
    "## Step 4: Split the Dataset\n",
    "Split the dataset into training (70%) and test (30%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b697a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "# Print the number of rows in each split\n",
    "print(f\"Training Rows: {train_data.count()}, Testing Rows: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a37714",
   "metadata": {},
   "source": [
    "## Step 5: Train a Decision Tree Model and Store It\n",
    "Train a Decision Tree model on the training data and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Train a Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=5)\n",
    "model = dt.fit(train_data)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = \"/home/Chapter 5/trained_model_decision_tree\"\n",
    "model.write().overwrite().save(model_path)\n",
    "\n",
    "print(f\"Model saved at: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf7646a",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the Model\n",
    "Calculate the confusion matrix, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion_matrix = predictions.groupBy(\"label\", \"prediction\").count()\n",
    "confusion_matrix.show()\n",
    "\n",
    "# Calculate Precision, Recall, and F1-Score\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4922fa",
   "metadata": {},
   "source": [
    "## Step 7: Plot the ROC Curve\n",
    "Generate the ROC curve and calculate the area under the curve (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate Area Under ROC (AUC)\n",
    "evaluator_roc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator_roc.evaluate(predictions)\n",
    "print(f\"Area Under ROC: {auc:.2f}\")\n",
    "\n",
    "# Extract probabilities, labels, and predictions\n",
    "probabilities = predictions.select(\"label\", col(\"probability\").alias(\"prob\")).collect()\n",
    "\n",
    "# Calculate TPR and FPR manually for the ROC curve\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "tpr_list, fpr_list = [], []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    tp = sum((prob[\"label\"] == 1) and (prob[\"prob\"][1] >= threshold) for prob in probabilities)\n",
    "    fp = sum((prob[\"label\"] == 0) and (prob[\"prob\"][1] >= threshold) for prob in probabilities)\n",
    "    fn = sum((prob[\"label\"] == 1) and (prob[\"prob\"][1] < threshold) for prob in probabilities)\n",
    "    tn = sum((prob[\"label\"] == 0) and (prob[\"prob\"][1] < threshold) for prob in probabilities)\n",
    "\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "    tpr_list.append(tpr)\n",
    "    fpr_list.append(fpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_list, tpr_list, label=f\"ROC Curve (AUC = {auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'r--', label=\"Random Classifier\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d31734-5ea0-4b7e-96a1-0ff3b03af095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4715f-3788-4fce-b68b-7cc8ee4434d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19143a6-1176-42e5-983f-c5241a3576b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60afa23-fcd0-49ba-9143-ca654e82c45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
