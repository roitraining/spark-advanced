{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca454bb",
   "metadata": {},
   "source": [
    "# Chapter 3: Resilient Distributed Datasets (RDDs)\n",
    "\n",
    "This notebook covers the core concepts of RDDs, including their creation, transformations, actions, persistence, and a real-world example (Word Count)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1548fcc8",
   "metadata": {},
   "source": [
    "## 1. Introduction to RDDs\n",
    "RDDs are the fundamental data structure in Apache Spark. They are:\n",
    "- Immutable: Once created, they cannot be changed.\n",
    "- Distributed: Data is partitioned across the nodes of a cluster.\n",
    "- Fault-Tolerant: Spark can recover RDDs in case of failures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361eadf",
   "metadata": {},
   "source": [
    "### 1.1 Creating RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a244d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"RDDExamples\").getOrCreate()\n",
    "\n",
    "# Creating an RDD from a list\n",
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "print(\"RDD Elements:\", rdd.collect())\n",
    "\n",
    "# Creating an RDD from an external file\n",
    "file_rdd = spark.sparkContext.textFile(\"word.txt\")\n",
    "print(\"File RDD Sample:\", file_rdd.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fef86a",
   "metadata": {},
   "source": [
    "## 2. Transformations\n",
    "Transformations create new RDDs from existing ones. They are **lazy**, meaning Spark doesnâ€™t execute them until an action is called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c97453",
   "metadata": {},
   "source": [
    "### 2.1 map() Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bfa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying a map() transformation\n",
    "squared_rdd = rdd.map(lambda x: x ** 2)\n",
    "print(\"Squared RDD:\", squared_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c514fd",
   "metadata": {},
   "source": [
    "### 2.2 flatMap() Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using flatMap() to split lines into words\n",
    "text_rdd = spark.sparkContext.parallelize([\"Hello world\", \"Apache Spark is great\"])\n",
    "words_rdd = text_rdd.flatMap(lambda line: line.split(\" \"))\n",
    "print(\"Words RDD:\", words_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f42226",
   "metadata": {},
   "source": [
    "### 2.3 filter() Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f104cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering even numbers from an RDD\n",
    "even_rdd = rdd.filter(lambda x: x % 2 == 0)\n",
    "print(\"Even Numbers:\", even_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae187c8a",
   "metadata": {},
   "source": [
    "## 3. Actions\n",
    "Actions trigger the execution of transformations. They return results or save data to an external storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0f5d2",
   "metadata": {},
   "source": [
    "### 3.1 collect() Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3583daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting all elements of an RDD\n",
    "collected_data = rdd.collect()\n",
    "print(\"Collected Data:\", collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c4137",
   "metadata": {},
   "source": [
    "### 3.2 reduce() Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing all elements in an RDD\n",
    "sum_result = rdd.reduce(lambda x, y: x + y)\n",
    "print(\"Sum of Elements:\", sum_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883bc171",
   "metadata": {},
   "source": [
    "### 3.3 count() and countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting elements in the RDD\n",
    "count = rdd.count()\n",
    "print(\"Number of Elements:\", count)\n",
    "\n",
    "# Counting occurrences of each value\n",
    "count_by_value = rdd.countByValue()\n",
    "print(\"Count by Value:\", dict(count_by_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c653f2",
   "metadata": {},
   "source": [
    "## 4. Persistence\n",
    "Persisting an RDD improves performance when the same data is reused multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persisting an RDD in memory\n",
    "cached_rdd = rdd.cache()\n",
    "print(\"Cached RDD Count:\", cached_rdd.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11f47e",
   "metadata": {},
   "source": [
    "## 5. Real-World Example: Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Word Count on a local text file\n",
    "text_file = spark.sparkContext.textFile(\"word.txt\")  # Make sure words.txt is in the same directory\n",
    "word_counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "                       .map(lambda word: (word, 1)) \\\n",
    "                       .reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "print(\"Word Counts:\", word_counts.collect())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8460557",
   "metadata": {},
   "source": [
    "## 6. Execution Plan\n",
    "Spark generates an execution plan to optimize transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the lineage of an RDD\n",
    "print(\"RDD Lineage:\", word_counts.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d672eea",
   "metadata": {},
   "source": [
    "## Chapter Summary\n",
    "In this notebook, we covered:\n",
    "- RDD creation\n",
    "- Transformations (map, flatMap, filter)\n",
    "- Actions (collect, reduce, count)\n",
    "- Persistence with cache()\n",
    "- Real-world example: Word Count\n",
    "- Execution plan and lineage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
