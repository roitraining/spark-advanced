{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates and Timestamps\n",
    "\n",
    "You will often find yourself working with Time and Date information, let's walk through some ways you can deal with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/02 13:48:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/02 13:48:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/11/02 13:48:20 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/11/02 13:48:20 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# May take a little while on a local computer\n",
    "spark = SparkSession.builder.appName(\"dates\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+----------+----------+---------+------------------+\n",
      "|      Date|      Open|              High|       Low|     Close|   Volume|         Adj Close|\n",
      "+----------+----------+------------------+----------+----------+---------+------------------+\n",
      "|2010-01-04|213.429998|        214.499996|212.380001|214.009998|123432400|         27.727039|\n",
      "|2010-01-05|214.599998|        215.589994|213.249994|214.379993|150476200|         27.774976|\n",
      "|2010-01-06|214.379993|            215.23|210.750004|210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|    211.75|        212.000006|209.050005|    210.58|119282800|          27.28265|\n",
      "|2010-01-08|210.299994|        212.000006|209.060005|211.980005|111902700|         27.464034|\n",
      "|2010-01-11|212.799997|        213.000002|208.450005|210.110003|115557400|         27.221758|\n",
      "|2010-01-12|209.189995|        209.769995|206.419998|207.720001|148614900|          26.91211|\n",
      "|2010-01-13|207.870005|        210.929995|204.099998|210.650002|151473000|          27.29172|\n",
      "|2010-01-14|210.110003|        210.459997|209.020004|    209.43|108223500|         27.133657|\n",
      "|2010-01-15|210.929995|211.59999700000003|205.869999|    205.93|148516900|         26.680198|\n",
      "|2010-01-19|208.330002|215.18999900000003|207.240004|215.039995|182501900|         27.860485|\n",
      "|2010-01-20|214.910006|        215.549994|209.500002|    211.73|153038200|         27.431644|\n",
      "|2010-01-21|212.079994|        213.309996|207.210003|208.069996|152038600|         26.957455|\n",
      "|2010-01-22|206.780006|        207.499996|    197.16|    197.75|220441900|         25.620401|\n",
      "|2010-01-25|202.510002|        204.699999|200.190002|203.070002|266424900|         26.309658|\n",
      "|2010-01-26|205.950001|        213.710005|202.580004|205.940001|466777500|         26.681494|\n",
      "|2010-01-27|206.849995|            210.58|199.530001|207.880005|430642100|          26.93284|\n",
      "|2010-01-28|204.930004|        205.500004|198.699995|199.289995|293375600|         25.819922|\n",
      "|2010-01-29|201.079996|        202.199995|190.250002|192.060003|311488100|         24.883208|\n",
      "|2010-02-01|192.369997|             196.0|191.299999|194.729998|187469100|         25.229131|\n",
      "+----------+----------+------------------+----------+----------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = spark.read.csv(\"appl_stock.csv\",header=True,inferSchema=True)\n",
    "import pandas as pd\n",
    "df = spark.createDataFrame(pd.read_csv(\"appl_stock.csv\",header='infer'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+----------+----------+---------+------------------+\n",
      "|      Date|      Open|              High|       Low|     Close|   Volume|         Adj Close|\n",
      "+----------+----------+------------------+----------+----------+---------+------------------+\n",
      "|2010-01-04|213.429998|        214.499996|212.380001|214.009998|123432400|         27.727039|\n",
      "|2010-01-05|214.599998|        215.589994|213.249994|214.379993|150476200|         27.774976|\n",
      "|2010-01-06|214.379993|            215.23|210.750004|210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|    211.75|        212.000006|209.050005|    210.58|119282800|          27.28265|\n",
      "|2010-01-08|210.299994|        212.000006|209.060005|211.980005|111902700|         27.464034|\n",
      "|2010-01-11|212.799997|        213.000002|208.450005|210.110003|115557400|         27.221758|\n",
      "|2010-01-12|209.189995|        209.769995|206.419998|207.720001|148614900|          26.91211|\n",
      "|2010-01-13|207.870005|        210.929995|204.099998|210.650002|151473000|          27.29172|\n",
      "|2010-01-14|210.110003|        210.459997|209.020004|    209.43|108223500|         27.133657|\n",
      "|2010-01-15|210.929995|211.59999700000003|205.869999|    205.93|148516900|         26.680198|\n",
      "|2010-01-19|208.330002|215.18999900000003|207.240004|215.039995|182501900|         27.860485|\n",
      "|2010-01-20|214.910006|        215.549994|209.500002|    211.73|153038200|         27.431644|\n",
      "|2010-01-21|212.079994|        213.309996|207.210003|208.069996|152038600|         26.957455|\n",
      "|2010-01-22|206.780006|        207.499996|    197.16|    197.75|220441900|         25.620401|\n",
      "|2010-01-25|202.510002|        204.699999|200.190002|203.070002|266424900|         26.309658|\n",
      "|2010-01-26|205.950001|        213.710005|202.580004|205.940001|466777500|         26.681494|\n",
      "|2010-01-27|206.849995|            210.58|199.530001|207.880005|430642100|          26.93284|\n",
      "|2010-01-28|204.930004|        205.500004|198.699995|199.289995|293375600|         25.819922|\n",
      "|2010-01-29|201.079996|        202.199995|190.250002|192.060003|311488100|         24.883208|\n",
      "|2010-02-01|192.369997|             196.0|191.299999|194.729998|187469100|         25.229131|\n",
      "+----------+----------+------------------+----------+----------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through how to grab parts of the timestamp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number,dayofmonth,hour,dayofyear,month,year,weekofyear,date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|dayofmonth(Date)|\n",
      "+----------------+\n",
      "|               4|\n",
      "|               5|\n",
      "|               6|\n",
      "|               7|\n",
      "|               8|\n",
      "|              11|\n",
      "|              12|\n",
      "|              13|\n",
      "|              14|\n",
      "|              15|\n",
      "|              19|\n",
      "|              20|\n",
      "|              21|\n",
      "|              22|\n",
      "|              25|\n",
      "|              26|\n",
      "|              27|\n",
      "|              28|\n",
      "|              29|\n",
      "|               1|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(dayofmonth(df['Date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|hour(Date)|\n",
      "+----------+\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(hour(df['Date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|dayofyear(Date)|\n",
      "+---------------+\n",
      "|              4|\n",
      "|              5|\n",
      "|              6|\n",
      "|              7|\n",
      "|              8|\n",
      "|             11|\n",
      "|             12|\n",
      "|             13|\n",
      "|             14|\n",
      "|             15|\n",
      "|             19|\n",
      "|             20|\n",
      "|             21|\n",
      "|             22|\n",
      "|             25|\n",
      "|             26|\n",
      "|             27|\n",
      "|             28|\n",
      "|             29|\n",
      "|             32|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(dayofyear(df['Date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|month(Date)|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          2|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(month(df['Date'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for example, let's say we wanted to know the average closing price per year. Easy! With a groupby and the year() function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|year(Date)|\n",
      "+----------+\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(year(df['Date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+----------+----------+---------+------------------+----+\n",
      "|      Date|      Open|              High|       Low|     Close|   Volume|         Adj Close|Year|\n",
      "+----------+----------+------------------+----------+----------+---------+------------------+----+\n",
      "|2010-01-04|213.429998|        214.499996|212.380001|214.009998|123432400|         27.727039|2010|\n",
      "|2010-01-05|214.599998|        215.589994|213.249994|214.379993|150476200|         27.774976|2010|\n",
      "|2010-01-06|214.379993|            215.23|210.750004|210.969995|138040000|27.333178000000004|2010|\n",
      "|2010-01-07|    211.75|        212.000006|209.050005|    210.58|119282800|          27.28265|2010|\n",
      "|2010-01-08|210.299994|        212.000006|209.060005|211.980005|111902700|         27.464034|2010|\n",
      "|2010-01-11|212.799997|        213.000002|208.450005|210.110003|115557400|         27.221758|2010|\n",
      "|2010-01-12|209.189995|        209.769995|206.419998|207.720001|148614900|          26.91211|2010|\n",
      "|2010-01-13|207.870005|        210.929995|204.099998|210.650002|151473000|          27.29172|2010|\n",
      "|2010-01-14|210.110003|        210.459997|209.020004|    209.43|108223500|         27.133657|2010|\n",
      "|2010-01-15|210.929995|211.59999700000003|205.869999|    205.93|148516900|         26.680198|2010|\n",
      "|2010-01-19|208.330002|215.18999900000003|207.240004|215.039995|182501900|         27.860485|2010|\n",
      "|2010-01-20|214.910006|        215.549994|209.500002|    211.73|153038200|         27.431644|2010|\n",
      "|2010-01-21|212.079994|        213.309996|207.210003|208.069996|152038600|         26.957455|2010|\n",
      "|2010-01-22|206.780006|        207.499996|    197.16|    197.75|220441900|         25.620401|2010|\n",
      "|2010-01-25|202.510002|        204.699999|200.190002|203.070002|266424900|         26.309658|2010|\n",
      "|2010-01-26|205.950001|        213.710005|202.580004|205.940001|466777500|         26.681494|2010|\n",
      "|2010-01-27|206.849995|            210.58|199.530001|207.880005|430642100|          26.93284|2010|\n",
      "|2010-01-28|204.930004|        205.500004|198.699995|199.289995|293375600|         25.819922|2010|\n",
      "|2010-01-29|201.079996|        202.199995|190.250002|192.060003|311488100|         24.883208|2010|\n",
      "|2010-02-01|192.369997|             196.0|191.299999|194.729998|187469100|         25.229131|2010|\n",
      "+----------+----------+------------------+----------+----------+---------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Year\",year(df['Date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|avg(Year)|        avg(Close)|\n",
      "+---------+------------------+\n",
      "|   2010.0| 259.8424600000001|\n",
      "|   2011.0| 364.0043253214286|\n",
      "|   2012.0| 576.0497195639999|\n",
      "|   2013.0|472.63488028571436|\n",
      "|   2014.0|295.40234165079374|\n",
      "|   2015.0|120.03999980555552|\n",
      "|   2016.0|104.60400786904763|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf = df.withColumn(\"Year\",year(df['Date']))\n",
    "newdf.groupBy(\"Year\").mean()[['avg(Year)','avg(Close)']].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not quite presentable! Let's use the .alias method as well as round() to clean this up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|  Year|Mean Close|\n",
      "+------+----------+\n",
      "|2010.0|    259.84|\n",
      "|2011.0|    364.00|\n",
      "|2012.0|    576.05|\n",
      "|2013.0|    472.63|\n",
      "|2014.0|    295.40|\n",
      "|2015.0|    120.04|\n",
      "|2016.0|    104.60|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = newdf.groupBy(\"Year\").mean()[['avg(Year)','avg(Close)']]\n",
    "result = result.withColumnRenamed(\"avg(Year)\",\"Year\")\n",
    "result = result.select('Year',format_number('avg(Close)',2).alias(\"Mean Close\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now you know how to work with Date and Timestamp information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
